# =======================================================================
# Platform Name            demo-trino-opa-platform
# Platform Stack:          trivadis/platys-modern-data-platform
# Platform Stack Version:  develop
# =======================================================================
networks:
  default:
    name: demo-trino-opa-platform
services:
  #  ================================== Open Policy Agent (opa) ========================================== #
  opa:
    image: openpolicyagent/opa:1.4.0
    container_name: opa
    hostname: opa
    labels:
      com.platys.name: opa
      com.platys.description: Open Policy Agent Server
      com.platys.restapi.title: Open Policy Agent (OPA) REST API
      com.platys.restapi.url: http://dataplatform:28332/v1/policies
    ports:
      - 28332:8181
    command:
      - run
      - --server
      - --addr=0.0.0.0:8181
      - --log-format=json-pretty
      - --set=decision_logs.console=true
      - --log-level=info
      - --watch
      - /data/policies
    volumes:
      - ./data-transfer:/data-transfer
      - ./security/opa/policies:/data/policies
    restart: unless-stopped
  #  ================================== Open Policy Administration Layer (OPAL) ========================================== #
  opal-server:
    image: permitio/opal-server:0.8.0
    container_name: opal-server
    hostname: opal-server
    labels:
      com.platys.name: opal
      com.platys.description: Open Policy Administration Layer
      com.platys.restapi.title: Open Policy Agent (OPA) REST API
      com.platys.restapi.url: http://dataplatform:7002
    ports:
      - 7002:7002
    environment:
      - OPAL_BROADCAST_URI=redis://redis-1:6379
      #Â number of uvicorn workers to run inside the opal-server container
      - UVICORN_NUM_WORKERS=2
      - OPAL_POLICY_SOURCE_TYPE=GIT
      - OPAL_POLICY_REPO_POLLING_INTERVAL=30
      - OPAL_POLICY_REPO_URL=https://github.com/nadavgross/trino-opa-example
      - OPAL_POLICY_REPO_MAIN_BRANCH=main
      - OPAL_DATA_CONFIG_SOURCES={"config":{"entries":[{"url":"http://opal-server:7002/policy-data","topics":["policy_data"],"dst_path":"/static"}]}}
      - OPAL_LOG_FORMAT_INCLUDE_PID=true
      - OPAL_POLICY_REPO_WEBHOOK_SECRET=1THQSpwrTz_Km41OGsGPAu2bgzP0WYhBt4eVnTtYVrc
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  opal-client:
    image: permitio/opal-client:0.8.0
    container_name: opal-client
    hostname: opal-client
    labels:
      com.platys.name: opal
      com.platys.description: Open Policy Administration Layer
      com.platys.restapi.title: Open Policy Agent (OPA) REST API
      com.platys.restapi.url: http://dataplatform:28407
    depends_on:
      - opal-server
    ports:
      - 28407:7000
      - 28408:8181
    environment:
      - OPAL_SERVER_URL=http://opal-server:7002
      - OPAL_LOG_FORMAT_INCLUDE_PID=true
      # - OPAL_OFFLINE_MODE_ENABLED=true
      - OPAL_DATA_TOPICS=policy_data
      - OPAL_POLICY_UPDATER_ENABLED=true
      - OPAL_INLINE_OPA_ENABLED=True
      # - OPAL_INLINE_OPA_CONFIG=
      - OPAL_INLINE_OPA_LOG_FORMAT=http
      - OPAL_OFFLINE_MODE_ENABLED=false
      - OPAL_POLICY_STORE_URL=http://opa:8181
      - OPAL_INLINE_CEDAR_ENABLED=False
    volumes:
      - ./data-transfer:/data-transfer
    command: sh -c "exec /usr/wait-for.sh opal-server:7002 --timeout=20 -- /start.sh"
    restart: unless-stopped
  #  ================================== Jupyter ========================================== #
  jupyter:
    image: quay.io/jupyter/minimal-notebook:latest
    container_name: jupyter
    hostname: jupyter
    labels:
      com.platys.name: jupyter
      com.platys.description: Web-based interactive development environment for notebooks, code, and data
      com.platys.webui.title: Jupyter UI
      com.platys.webui.url: http://dataplatform:28888
      com.platys.password.envvars: PLATYS_JUPYTER_TOKEN,PLATYS_AWS_SECRET_ACCESS_KEY
    ports:
      - 28888:8888
    user: root
    extra_hosts:
      - host.docker.internal:host-gateway
    environment:
      JUPYTER_ENABLE_LAB: "'yes'"
      GRANT_SUDO: "'yes'"
      JUPYTER_TOKEN: ${PLATYS_JUPYTER_TOKEN:-abc123!}
      DOCKER_STACKS_JUPYTER_CMD: lab
      MAVEN_DOWNLOAD_JARS: com.amazonaws:aws-java-sdk-bundle:1.12.262,org.apache.hadoop:hadoop-aws:3.3.4,com.google.guava:guava:27.1-jre
      # remove some JARS if they are conflicting with the ones installed above
      REMOVE_JARS: guava-14.0.1.jar
      # for awscli & s3cmd
      AWS_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      AWS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      AWS_ENDPOINT: http://minio-1:9000
      AWS_REGION: us-east-1
      AWS_DEFAULT_REGION: us-east-1
    volumes:
      - ./data-transfer:/data-transfer
      - ./init/jupyter/on-startup-jupyter/:/usr/local/bin/start-notebook.d/
      - ./init/jupyter/on-startup-jupyter-finished/:/usr/local/bin/before-notebook.d/
      - ./init/jupyter/on-startup-notebook-kernel:/home/jovyan/.ipython/profile_default/startup/
      - ./scripts/docker/maven-download.sh:/maven-download.sh
    command:
      # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
      - bash
      - -c
      - |
        conda create -y --name py312 python=3.12.8
        source /opt/conda/etc/profile.d/conda.sh
        conda activate py312
        pip install ipykernel    
        python -m ipykernel install --user --name py312 --display-name "Python 3.12.8 (ipykernel)"
        start-notebook.sh
    restart: unless-stopped
  #  ================================== Redis ========================================== #
  redis-1:
    image: bitnami/redis:7.4
    hostname: redis-1
    container_name: redis-1
    labels:
      com.platys.name: redis
      com.platys.description: Key-value store
    ports:
      - 6379:6379
    environment:
      - REDIS_PORT_NUMBER=6379
      - ALLOW_EMPTY_PASSWORD=yes
      - REDIS_AOF_ENABLED=yes
      - REDIS_RDB_POLICY_DISABLED=yes
    volumes:
      - ./data-transfer:/data-transfer
    command: /opt/bitnami/scripts/redis/run.sh --loglevel notice
    restart: unless-stopped
    healthcheck:
      test: [CMD-SHELL, redis-cli --no-auth-warning ping | grep PONG]
      interval: 5s
      timeout: 3s
      retries: 5
  #  ================================== MongoDB ========================================== #
  mongo-1:
    image: mongo:8
    container_name: mongo-1
    hostname: mongo-1
    labels:
      com.platys.name: mongodb
      com.platys.description: Document NoSQL database
      com.platys.password.envvars: PLATYS_MONGO_PASSWORD
    ports:
      - 27017:27017
    environment:
      - MONGO_DATA_DIR=/data/db
      - MONGO_LOG_DIR=/data/log
    volumes:
      - ./data-transfer:/data-transfer
      # seeding scripts
      - ./init/mongodb:/docker-entrypoint-initdb.d
    restart: unless-stopped
  #  ================================== PostgreSQL ========================================== #
  postgresql:
    image: postgres:17
    container_name: postgresql
    hostname: postgresql
    labels:
      com.platys.name: postgresql
      com.platys.description: Open-Source object-relational database system
      com.platys.password.envvars: PLATYS_POSTGRESQL_PASSWORD,PLATYS_POSTGRESQL_MULTIPLE_PASSWORD
    ports:
      - 5432:5432
    environment:
      - POSTGRES_PASSWORD=${PLATYS_POSTGRESQL_PASSWORD:-abc123!}
      - POSTGRES_USER=postgres
      - POSTGRES_DB=postgres
      - POSTGRES_MULTIPLE_DATABASES=datalake_catalog
      - POSTGRES_MULTIPLE_USERS=iceberg
      - POSTGRES_MULTIPLE_PASSWORDS=${PLATYS_POSTGRESQL_MULTIPLE_PASSWORD:-abc123!}
      - POSTGRES_MULTIPLE_ADDL_ROLES=
      - PGDATA=/var/lib/postgresql/data/pgdata
      - DB_SCHEMA=demo
    volumes:
      - ./data-transfer:/data-transfer
      - ./init/postgresql:/docker-entrypoint-initdb.d/
    restart: unless-stopped
    healthcheck:
      test: [CMD-SHELL, pg_isready -U postgres]
      interval: 10s
      timeout: 5s
      retries: 5
  #  ================================== Trino ========================================== #
  trino-1:
    image: trinodb/trino:475
    hostname: trino-1
    container_name: trino-1
    labels:
      com.platys.name: trino
      com.platys.description: SQL Virtualization Engine
      com.platys.webui.title: Trino UI
      com.platys.webui.url: https://dataplatform:28083/ui/preview
    ports:
      - 28082:8080
      - 28083:8443
    environment:
      # this is only generated to keep the structure valid if no other env variables are present
      DUMMY: make-it-valid
      S3_ENDPOINT: http://minio-1:9000
      S3_REGION: us-east-1
      S3_AWS_ACCESS_KEY: ${PLATYS_AWS_ACCESS_KEY:-admin}
      S3_AWS_SECRET_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      S3_PATH_STYLE_ACCESS: 'true'
      HIVE_STORAGE_FORMAT: ORC
      HIVE_COMPRESSION_CODEC: GZIP
      HIVE_VIEWS_ENABLED: 'false'
      HIVE_RUN_AS_INVOKER: 'false'
      HIVE_LEGACY_TRANSLATION: 'false'
      NESSIE_CATALOG_WAREHOUSE_DIR: s3a://admin-bucket/nessie/warehouse
      ICEBERG_REST_CATALOG_URI: http://iceberg-rest-catalog:8181
      ICEBERG_REST_CATALOG_WAREHOUSE: s3a://datalake/
      POSTGRESQL_DATABASE: postgres
      POSTGRESQL_USER: postgres
      POSTGRESQL_PASSWORD: abc123!
      REDIS_TABLE_NAMES: ''
      REDIS_NODES: redis-1:6379
      EVENT_LISTENER_CONFIG_FILES: ''
      OPA_ENDPOINT: http://opa:8181
      OPA_NAMESPACE: policies
    volumes:
      - ./data-transfer:/data-transfer
      - ./conf/trino/single/config-auth.properties:/etc/trino/config.properties
      - ./conf/trino/single/node.properties:/etc/trino/node.properties
      - ./conf/trino/single/log-debug.properties:/etc/trino/log.properties
      - ./conf/trino/catalog/minio.properties:/etc/trino/catalog/minio.properties
      - ./conf/trino/catalog/iceberg-rest.properties:/etc/trino/catalog/datalake.properties
      - ./conf/trino/catalog/iceberg.properties:/etc/trino/catalog/iceberg.properties
      - ./conf/trino/catalog/postgresql.properties:/etc/trino/catalog/postgresql.properties
      - ./conf/trino/catalog/redis.properties:/etc/trino/catalog/redis.properties
      - ./conf/trino/catalog/mongo.properties:/etc/trino/catalog/mongo.properties
      - ./security/trino/password-authenticator.properties:/etc/trino/password-authenticator.properties
      - ./security/trino/password.db:/etc/trino/password.db
      - ./security/trino/certs:/etc/trino/certs
      - ./security/trino/access-control-opa.properties:/etc/trino/access-control.properties
      - ./custom-conf/trino/security:/etc/trino/security
      - ./conf/trino/single/log-debug.properties:/etc/trino/log.properties
    restart: unless-stopped
    healthcheck:
      test: [CMD-SHELL, trino --version]
      interval: 5s
      timeout: 5s
      retries: 5
  trino-cli:
    image: trivadis/trino-cli:latest
    hostname: trino-cli
    container_name: trino-cli
    labels:
      com.platys.name: trino
      com.platys.description: Trino CLI
    volumes:
      - ./data-transfer:/data-transfer
    tty: true
    restart: unless-stopped
  #  ================================== Minio ========================================== #
  minio-1:
    image: minio/minio:RELEASE.2025-04-22T22-12-26Z
    container_name: minio-1
    hostname: minio-1
    labels:
      com.platys.name: minio
      com.platys.description: Software-defined Object Storage
      com.platys.webui.title: MinIO UI
      com.platys.webui.url: http://dataplatform:9010
      com.platys.password.envvars: PLATYS_AWS_SECRET_ACCESS_KEY
    ports:
      # S3 API Port
      - 9000:9000
      # UI Port
      - 9010:9010
    environment:
      MINIO_ROOT_USER: ${PLATYS_AWS_ACCESS_KEY:-admin}
      MINIO_ROOT_PASSWORD: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      # remove region due to problems with RisingWave
      #MINIO_REGION_NAME: us-east-1
      #MINIO_REGION: us-east-1
      MINIO_DOMAIN: minio
      MINIO_SERVER_URL: http://${PUBLIC_IP}:9000
      MINIO_COMPRESSION_ENABLE: off
      MINIO_PROMETHEUS_AUTH_TYPE: public
      MINIO_PROMETHEUS_URL: http://prometheus-1:9090
    volumes:
      - ./data-transfer:/data-transfer
    command: server /data --console-address ":9010"
    restart: unless-stopped
    healthcheck:
      test: [CMD, curl, -f, http://minio-1:9000/minio/health/live]
      interval: 15s
      timeout: 20s
      retries: 3
  #  ================================== Minio MC ========================================== #
  minio-mc:
    image: minio/mc:latest
    container_name: minio-mc
    hostname: minio-mc
    labels:
      com.platys.name: minio
      com.platys.description: MinIO Console
    environment:
      # these two env variables are also needed for the s3-credentials.properties file gen to work! 
      AWS_ACCESS_KEY: ${PLATYS_AWS_ACCESS_KEY:-admin}
      AWS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      MC_HOST_minio-1: http://${PLATYS_AWS_ACCESS_KEY:-admin}:${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}@minio-1:9000
    volumes:
      - ./data-transfer:/data-transfer
      - ./scripts/docker/wait-for-it.sh:/usr/src/app/wait-for-it.sh
      - ./security/aws/credentials:/tmp/credentials.templ
      - aws-credentials-vol:/tmp/.aws:RO
    entrypoint:
      - /bin/sh
      - -c
      - |
        /usr/src/app/wait-for-it.sh -t 180 minio-1:9000
        mkdir -p /tmp/.aws
        eval "echo \"$$(cat /tmp/credentials.templ)\"" >> /tmp/.aws/credentials
        mc mb --ignore-existing minio-1/admin-bucket
              for bucket in $$(tr ',' '\n' <<< "datalake")
        do
          mc mb --ignore-existing minio-1/$$bucket
        done
        #
        while [ 1 -eq 1 ];do sleep 60;done
    restart: unless-stopped
  #  ================================== Iceberg REST Catalog ========================================== #
  iceberg-rest-catalog:
    image: tabulario/iceberg-rest:1.6.0
    container_name: iceberg-rest-catalog
    hostname: iceberg-rest-catalog
    labels:
      com.platys.name: iceberg-rest-catalog
      com.platys.description: Iceberg Rest Catalog
      com.platys.restapi.title: Iceberg REST Catalog
      com.platys.restapi.url: http://dataplatform:28287/v1/namespaces
      com.platys.password.envvars: PLATYS_ICEBERG_REST_CATALOG_POSTGRESQL_PASSWORD
    ports:
      - 28287:8181
    environment:
      REST_PORT: 8181
      CATALOG_IO__IMPL: org.apache.iceberg.aws.s3.S3FileIO
      AWS_ACCESS_KEY_ID: ${PLATYS_AWS_ACCESS_KEY:-admin}
      AWS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-abc123abc123!}
      AWS_REGION: us-east-1
      CATALOG_S3_PATH-STYLE-ACCESS: true
      CATALOG_S3_ENDPOINT: http://minio-1:9000
      CATALOG_WAREHOUSE: s3a://datalake/
      CATALOG_CATALOG__IMPL: org.apache.iceberg.jdbc.JdbcCatalog
      CATALOG_URI: jdbc:sqlite:file:/tmp/iceberg_rest_mode=memory
      CATALOG_JDBC_USER: iceberg
      CATALOG_JDBC_PASSWORD: ${PLATYS_ICEBERG_REST_CATALOG_POSTGRESQL_PASSWORD:-abc123!}
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== markdown-viewer ========================================== #
  markdown-viewer:
    image: dannyben/madness:latest
    container_name: markdown-viewer
    hostname: markdown-viewer
    labels:
      com.platys.name: markdown-viewer
      com.platys.description: Platys Platform homepage viewer
      com.platys.webui.title: Markdown Viewer UI
      com.platys.webui.url: http://dataplatform:80
    ports:
      - 80:3000
    volumes:
      - ./artefacts:/docs
      - ./conf/markdown-viewer/markdown-madness.yml:/docs/.madness.yml
      - ./data-transfer:/data-transfer
    command: server
    restart: unless-stopped
    healthcheck:
      test: [CMD-SHELL, curl -f http://markdown-viewer:3000 || exit 1]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 1m
  markdown-renderer:
    image: trivadis/jinja2-renderer:latest
    container_name: markdown-renderer
    hostname: markdown-renderer
    labels:
      com.platys.name: markdown-renderer
      com.platys.description: Platys Platform homepage rendering
    environment:
      USE_PUBLIC_IP: 'True'
      PUBLIC_IP: ${PUBLIC_IP}
      DOCKER_HOST_IP: ${DOCKER_HOST_IP}
      DATAPLATFORM_HOME: ${DATAPLATFORM_HOME}
      PLATYS_PLATFORM_NAME: demo-trino-opa-platform
      PLATYS_PLATFORM_STACK: trivadis/platys-modern-data-platform
      PLATYS_PLATFORM_STACK_VERSION: develop
      PLATYS_COPY_COOKBOOK_DATA: 'True'
      SERVICE_LIST_VERSION: 2
    volumes:
      - ./artefacts/templates:/templates
      - ./artefacts/templates:/scripts
      - .:/variables
      - ./artefacts:/output
      - ./data-transfer:/data-transfer
    init: true
volumes:
  data-transfer-vol:
    name: data_transfer_vol
  aws-credentials-vol:
